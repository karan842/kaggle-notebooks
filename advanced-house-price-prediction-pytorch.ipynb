{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Advances House Price Prediction using PyTorch","metadata":{}},{"cell_type":"markdown","source":"### Importing Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\nimport warnings\nwarnings.filterwarnings('ignore')\nimport torch\nimport torch.nn as nn","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:35:54.097526Z","iopub.execute_input":"2022-06-03T09:35:54.098222Z","iopub.status.idle":"2022-06-03T09:35:54.103987Z","shell.execute_reply.started":"2022-06-03T09:35:54.098180Z","shell.execute_reply":"2022-06-03T09:35:54.102746Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"# importing datasets\ndf = pd.read_csv('https://raw.githubusercontent.com/krishnaik06/Pytorch-Tutorial/master/houseprice.csv',usecols=[\"SalePrice\", \"MSSubClass\", \"MSZoning\", \"LotFrontage\", \"LotArea\",\n                                         \"Street\", \"YearBuilt\", \"LotShape\", \"1stFlrSF\", \"2ndFlrSF\"]).dropna()","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:35:54.278535Z","iopub.execute_input":"2022-06-03T09:35:54.279039Z","iopub.status.idle":"2022-06-03T09:35:54.725877Z","shell.execute_reply.started":"2022-06-03T09:35:54.279004Z","shell.execute_reply":"2022-06-03T09:35:54.725100Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"# exploring the data\ndef exp_data(data):\n    print(\"Shape of the data: \")\n    print(df.shape)\n    print(\"-\"*80)\n    print(\"Columns in the data: \")\n    print(df.columns)\n    print(\"-\"*80)\n    print(\"Information of the data: \")\n    print(df.info())\n    print(\"-\"*80)\n    print(\"Description of the data: \")\n    print(df.describe())\n    print(\"-\"*80)\n    print(\"Top 5 records: \")\n    print(df.head(5))\n    \n    \n# calling the function\nexp_data(df)","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:35:54.727383Z","iopub.execute_input":"2022-06-03T09:35:54.727750Z","iopub.status.idle":"2022-06-03T09:35:54.769137Z","shell.execute_reply.started":"2022-06-03T09:35:54.727714Z","shell.execute_reply":"2022-06-03T09:35:54.768365Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stdout","text":"Shape of the data: \n(1201, 10)\n--------------------------------------------------------------------------------\nColumns in the data: \nIndex(['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n       'LotShape', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'SalePrice'],\n      dtype='object')\n--------------------------------------------------------------------------------\nInformation of the data: \n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 1201 entries, 0 to 1459\nData columns (total 10 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   MSSubClass   1201 non-null   int64  \n 1   MSZoning     1201 non-null   object \n 2   LotFrontage  1201 non-null   float64\n 3   LotArea      1201 non-null   int64  \n 4   Street       1201 non-null   object \n 5   LotShape     1201 non-null   object \n 6   YearBuilt    1201 non-null   int64  \n 7   1stFlrSF     1201 non-null   int64  \n 8   2ndFlrSF     1201 non-null   int64  \n 9   SalePrice    1201 non-null   int64  \ndtypes: float64(1), int64(6), object(3)\nmemory usage: 103.2+ KB\nNone\n--------------------------------------------------------------------------------\nDescription of the data: \n        MSSubClass  LotFrontage        LotArea    YearBuilt     1stFlrSF  \\\ncount  1201.000000  1201.000000    1201.000000  1201.000000  1201.000000   \nmean     57.198168    70.049958    9951.698585  1970.580350  1158.437968   \nstd      43.106427    24.284752    7924.353975    31.750335   386.257235   \nmin      20.000000    21.000000    1300.000000  1872.000000   334.000000   \n25%      20.000000    59.000000    7420.000000  1950.000000   876.000000   \n50%      50.000000    69.000000    9262.000000  1972.000000  1082.000000   \n75%      70.000000    80.000000   11249.000000  2003.000000  1383.000000   \nmax     190.000000   313.000000  215245.000000  2010.000000  4692.000000   \n\n          2ndFlrSF      SalePrice  \ncount  1201.000000    1201.000000  \nmean    346.073272  180770.480433  \nstd     435.143451   83389.519866  \nmin       0.000000   34900.000000  \n25%       0.000000  127500.000000  \n50%       0.000000  159500.000000  \n75%     728.000000  213500.000000  \nmax    2065.000000  755000.000000  \n--------------------------------------------------------------------------------\nTop 5 records: \n   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape  YearBuilt  \\\n0          60       RL         65.0     8450   Pave      Reg       2003   \n1          20       RL         80.0     9600   Pave      Reg       1976   \n2          60       RL         68.0    11250   Pave      IR1       2001   \n3          70       RL         60.0     9550   Pave      IR1       1915   \n4          60       RL         84.0    14260   Pave      IR1       2000   \n\n   1stFlrSF  2ndFlrSF  SalePrice  \n0       856       854     208500  \n1      1262         0     181500  \n2       920       866     223500  \n3       961       756     140000  \n4      1145      1053     250000  \n","output_type":"stream"}]},{"cell_type":"code","source":"# Unique values in the column name\nfor i in df.columns:\n    print(\"Column name {} and unique values are {}\".format(i,len(df[i].unique())))","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:35:54.770228Z","iopub.execute_input":"2022-06-03T09:35:54.770577Z","iopub.status.idle":"2022-06-03T09:35:54.778358Z","shell.execute_reply.started":"2022-06-03T09:35:54.770540Z","shell.execute_reply":"2022-06-03T09:35:54.777585Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stdout","text":"Column name MSSubClass and unique values are 15\nColumn name MSZoning and unique values are 5\nColumn name LotFrontage and unique values are 110\nColumn name LotArea and unique values are 869\nColumn name Street and unique values are 2\nColumn name LotShape and unique values are 4\nColumn name YearBuilt and unique values are 112\nColumn name 1stFlrSF and unique values are 678\nColumn name 2ndFlrSF and unique values are 368\nColumn name SalePrice and unique values are 597\n","output_type":"stream"}]},{"cell_type":"code","source":"import datetime\ndatetime.datetime.now().year","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:35:54.780222Z","iopub.execute_input":"2022-06-03T09:35:54.780860Z","iopub.status.idle":"2022-06-03T09:35:54.787574Z","shell.execute_reply.started":"2022-06-03T09:35:54.780822Z","shell.execute_reply":"2022-06-03T09:35:54.786806Z"},"trusted":true},"execution_count":82,"outputs":[{"execution_count":82,"output_type":"execute_result","data":{"text/plain":"2022"},"metadata":{}}]},{"cell_type":"code","source":"# Total years\ndf['Total Years'] = datetime.datetime.now().year-df['YearBuilt']","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:35:54.898152Z","iopub.execute_input":"2022-06-03T09:35:54.898554Z","iopub.status.idle":"2022-06-03T09:35:54.904690Z","shell.execute_reply.started":"2022-06-03T09:35:54.898525Z","shell.execute_reply":"2022-06-03T09:35:54.903822Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:35:55.057938Z","iopub.execute_input":"2022-06-03T09:35:55.058564Z","iopub.status.idle":"2022-06-03T09:35:55.072501Z","shell.execute_reply.started":"2022-06-03T09:35:55.058529Z","shell.execute_reply":"2022-06-03T09:35:55.071700Z"},"trusted":true},"execution_count":84,"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape  YearBuilt  \\\n0          60       RL         65.0     8450   Pave      Reg       2003   \n1          20       RL         80.0     9600   Pave      Reg       1976   \n2          60       RL         68.0    11250   Pave      IR1       2001   \n3          70       RL         60.0     9550   Pave      IR1       1915   \n4          60       RL         84.0    14260   Pave      IR1       2000   \n\n   1stFlrSF  2ndFlrSF  SalePrice  Total Years  \n0       856       854     208500           19  \n1      1262         0     181500           46  \n2       920       866     223500           21  \n3       961       756     140000          107  \n4      1145      1053     250000           22  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MSSubClass</th>\n      <th>MSZoning</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>Street</th>\n      <th>LotShape</th>\n      <th>YearBuilt</th>\n      <th>1stFlrSF</th>\n      <th>2ndFlrSF</th>\n      <th>SalePrice</th>\n      <th>Total Years</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>60</td>\n      <td>RL</td>\n      <td>65.0</td>\n      <td>8450</td>\n      <td>Pave</td>\n      <td>Reg</td>\n      <td>2003</td>\n      <td>856</td>\n      <td>854</td>\n      <td>208500</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20</td>\n      <td>RL</td>\n      <td>80.0</td>\n      <td>9600</td>\n      <td>Pave</td>\n      <td>Reg</td>\n      <td>1976</td>\n      <td>1262</td>\n      <td>0</td>\n      <td>181500</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>60</td>\n      <td>RL</td>\n      <td>68.0</td>\n      <td>11250</td>\n      <td>Pave</td>\n      <td>IR1</td>\n      <td>2001</td>\n      <td>920</td>\n      <td>866</td>\n      <td>223500</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>70</td>\n      <td>RL</td>\n      <td>60.0</td>\n      <td>9550</td>\n      <td>Pave</td>\n      <td>IR1</td>\n      <td>1915</td>\n      <td>961</td>\n      <td>756</td>\n      <td>140000</td>\n      <td>107</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>60</td>\n      <td>RL</td>\n      <td>84.0</td>\n      <td>14260</td>\n      <td>Pave</td>\n      <td>IR1</td>\n      <td>2000</td>\n      <td>1145</td>\n      <td>1053</td>\n      <td>250000</td>\n      <td>22</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.drop(\"YearBuilt\", axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:35:55.237192Z","iopub.execute_input":"2022-06-03T09:35:55.239239Z","iopub.status.idle":"2022-06-03T09:35:55.245467Z","shell.execute_reply.started":"2022-06-03T09:35:55.239209Z","shell.execute_reply":"2022-06-03T09:35:55.244688Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:35:55.402332Z","iopub.execute_input":"2022-06-03T09:35:55.402636Z","iopub.status.idle":"2022-06-03T09:35:55.409549Z","shell.execute_reply.started":"2022-06-03T09:35:55.402609Z","shell.execute_reply":"2022-06-03T09:35:55.408633Z"},"trusted":true},"execution_count":86,"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"Index(['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n       'LotShape', '1stFlrSF', '2ndFlrSF', 'SalePrice', 'Total Years'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"cat_features = ['MSSubClass', 'MSZoning', 'Street', 'LotShape']\nout_feature = 'SalePrice'","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:35:55.637832Z","iopub.execute_input":"2022-06-03T09:35:55.638489Z","iopub.status.idle":"2022-06-03T09:35:55.643270Z","shell.execute_reply.started":"2022-06-03T09:35:55.638450Z","shell.execute_reply":"2022-06-03T09:35:55.642275Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"df['MSSubClass'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:35:55.857552Z","iopub.execute_input":"2022-06-03T09:35:55.858223Z","iopub.status.idle":"2022-06-03T09:35:55.865258Z","shell.execute_reply.started":"2022-06-03T09:35:55.858185Z","shell.execute_reply":"2022-06-03T09:35:55.864414Z"},"trusted":true},"execution_count":88,"outputs":[{"execution_count":88,"output_type":"execute_result","data":{"text/plain":"array([ 60,  20,  70,  50, 190,  45,  90, 120,  30,  80, 160,  75, 180,\n        40,  85])"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlbl_encoder = {}\nlbl_encoder['MSSubClass'] = LabelEncoder()\nlbl_encoder['MSSubClass'].fit_transform(df['MSSubClass'])","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:35:56.018086Z","iopub.execute_input":"2022-06-03T09:35:56.019088Z","iopub.status.idle":"2022-06-03T09:35:56.026543Z","shell.execute_reply.started":"2022-06-03T09:35:56.019039Z","shell.execute_reply":"2022-06-03T09:35:56.025658Z"},"trusted":true},"execution_count":89,"outputs":[{"execution_count":89,"output_type":"execute_result","data":{"text/plain":"array([5, 0, 5, ..., 6, 0, 0])"},"metadata":{}}]},{"cell_type":"code","source":"lbl_encoder","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:35:56.203100Z","iopub.execute_input":"2022-06-03T09:35:56.203856Z","iopub.status.idle":"2022-06-03T09:35:56.209973Z","shell.execute_reply.started":"2022-06-03T09:35:56.203817Z","shell.execute_reply":"2022-06-03T09:35:56.209153Z"},"trusted":true},"execution_count":90,"outputs":[{"execution_count":90,"output_type":"execute_result","data":{"text/plain":"{'MSSubClass': LabelEncoder()}"},"metadata":{}}]},{"cell_type":"code","source":"#mfor every category\nlbl_encoders = {}\nfor feature in cat_features:\n    lbl_encoders[feature] = LabelEncoder()\n    df[feature] = lbl_encoders[feature].fit_transform(df[feature])","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:35:56.336904Z","iopub.execute_input":"2022-06-03T09:35:56.337665Z","iopub.status.idle":"2022-06-03T09:35:56.345783Z","shell.execute_reply.started":"2022-06-03T09:35:56.337628Z","shell.execute_reply":"2022-06-03T09:35:56.344950Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:35:56.477371Z","iopub.execute_input":"2022-06-03T09:35:56.478043Z","iopub.status.idle":"2022-06-03T09:35:56.496109Z","shell.execute_reply.started":"2022-06-03T09:35:56.478011Z","shell.execute_reply":"2022-06-03T09:35:56.495334Z"},"trusted":true},"execution_count":92,"outputs":[{"execution_count":92,"output_type":"execute_result","data":{"text/plain":"      MSSubClass  MSZoning  LotFrontage  LotArea  Street  LotShape  1stFlrSF  \\\n0              5         3         65.0     8450       1         3       856   \n1              0         3         80.0     9600       1         3      1262   \n2              5         3         68.0    11250       1         0       920   \n3              6         3         60.0     9550       1         0       961   \n4              5         3         84.0    14260       1         0      1145   \n...          ...       ...          ...      ...     ...       ...       ...   \n1455           5         3         62.0     7917       1         3       953   \n1456           0         3         85.0    13175       1         3      2073   \n1457           6         3         66.0     9042       1         3      1188   \n1458           0         3         68.0     9717       1         3      1078   \n1459           0         3         75.0     9937       1         3      1256   \n\n      2ndFlrSF  SalePrice  Total Years  \n0          854     208500           19  \n1            0     181500           46  \n2          866     223500           21  \n3          756     140000          107  \n4         1053     250000           22  \n...        ...        ...          ...  \n1455       694     175000           23  \n1456         0     210000           44  \n1457      1152     266500           81  \n1458         0     142125           72  \n1459         0     147500           57  \n\n[1201 rows x 10 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MSSubClass</th>\n      <th>MSZoning</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>Street</th>\n      <th>LotShape</th>\n      <th>1stFlrSF</th>\n      <th>2ndFlrSF</th>\n      <th>SalePrice</th>\n      <th>Total Years</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>3</td>\n      <td>65.0</td>\n      <td>8450</td>\n      <td>1</td>\n      <td>3</td>\n      <td>856</td>\n      <td>854</td>\n      <td>208500</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>3</td>\n      <td>80.0</td>\n      <td>9600</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1262</td>\n      <td>0</td>\n      <td>181500</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>3</td>\n      <td>68.0</td>\n      <td>11250</td>\n      <td>1</td>\n      <td>0</td>\n      <td>920</td>\n      <td>866</td>\n      <td>223500</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>3</td>\n      <td>60.0</td>\n      <td>9550</td>\n      <td>1</td>\n      <td>0</td>\n      <td>961</td>\n      <td>756</td>\n      <td>140000</td>\n      <td>107</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>3</td>\n      <td>84.0</td>\n      <td>14260</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1145</td>\n      <td>1053</td>\n      <td>250000</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1455</th>\n      <td>5</td>\n      <td>3</td>\n      <td>62.0</td>\n      <td>7917</td>\n      <td>1</td>\n      <td>3</td>\n      <td>953</td>\n      <td>694</td>\n      <td>175000</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>1456</th>\n      <td>0</td>\n      <td>3</td>\n      <td>85.0</td>\n      <td>13175</td>\n      <td>1</td>\n      <td>3</td>\n      <td>2073</td>\n      <td>0</td>\n      <td>210000</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>1457</th>\n      <td>6</td>\n      <td>3</td>\n      <td>66.0</td>\n      <td>9042</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1188</td>\n      <td>1152</td>\n      <td>266500</td>\n      <td>81</td>\n    </tr>\n    <tr>\n      <th>1458</th>\n      <td>0</td>\n      <td>3</td>\n      <td>68.0</td>\n      <td>9717</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1078</td>\n      <td>0</td>\n      <td>142125</td>\n      <td>72</td>\n    </tr>\n    <tr>\n      <th>1459</th>\n      <td>0</td>\n      <td>3</td>\n      <td>75.0</td>\n      <td>9937</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1256</td>\n      <td>0</td>\n      <td>147500</td>\n      <td>57</td>\n    </tr>\n  </tbody>\n</table>\n<p>1201 rows Ã— 10 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# stacking and converting into tensors\ncat_features = np.stack([df['MSSubClass'], df['MSZoning'], df['Street'], df['LotShape']],1)","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:35:56.619723Z","iopub.execute_input":"2022-06-03T09:35:56.620221Z","iopub.status.idle":"2022-06-03T09:35:56.624828Z","shell.execute_reply.started":"2022-06-03T09:35:56.620186Z","shell.execute_reply":"2022-06-03T09:35:56.624083Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"cat_features","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:35:56.776896Z","iopub.execute_input":"2022-06-03T09:35:56.777615Z","iopub.status.idle":"2022-06-03T09:35:56.786170Z","shell.execute_reply.started":"2022-06-03T09:35:56.777586Z","shell.execute_reply":"2022-06-03T09:35:56.785404Z"},"trusted":true},"execution_count":94,"outputs":[{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"array([[5, 3, 1, 3],\n       [0, 3, 1, 3],\n       [5, 3, 1, 0],\n       ...,\n       [6, 3, 1, 3],\n       [0, 3, 1, 3],\n       [0, 3, 1, 3]])"},"metadata":{}}]},{"cell_type":"code","source":"## convert numpy into tensorws\ncat_features = torch.tensor(cat_features, dtype=torch.int64)\ncat_features","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:35:56.957239Z","iopub.execute_input":"2022-06-03T09:35:56.957565Z","iopub.status.idle":"2022-06-03T09:35:56.964904Z","shell.execute_reply.started":"2022-06-03T09:35:56.957538Z","shell.execute_reply":"2022-06-03T09:35:56.963934Z"},"trusted":true},"execution_count":95,"outputs":[{"execution_count":95,"output_type":"execute_result","data":{"text/plain":"tensor([[5, 3, 1, 3],\n        [0, 3, 1, 3],\n        [5, 3, 1, 0],\n        ...,\n        [6, 3, 1, 3],\n        [0, 3, 1, 3],\n        [0, 3, 1, 3]])"},"metadata":{}}]},{"cell_type":"code","source":"## create continous variable\ncont_features = []\nfor i in df.columns:\n    if i in ['MSSubClass', 'MSZoning', 'Street', 'LotShape', 'SalePrice']:\n        pass\n    else:\n        cont_features.append(i)","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:35:57.107536Z","iopub.execute_input":"2022-06-03T09:35:57.108247Z","iopub.status.idle":"2022-06-03T09:35:57.112873Z","shell.execute_reply.started":"2022-06-03T09:35:57.108211Z","shell.execute_reply":"2022-06-03T09:35:57.112088Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"cont_features","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:35:57.277106Z","iopub.execute_input":"2022-06-03T09:35:57.277793Z","iopub.status.idle":"2022-06-03T09:35:57.283158Z","shell.execute_reply.started":"2022-06-03T09:35:57.277764Z","shell.execute_reply":"2022-06-03T09:35:57.282327Z"},"trusted":true},"execution_count":97,"outputs":[{"execution_count":97,"output_type":"execute_result","data":{"text/plain":"['LotFrontage', 'LotArea', '1stFlrSF', '2ndFlrSF', 'Total Years']"},"metadata":{}}]},{"cell_type":"code","source":"## stacking continous variable to a tensor\ncont_values = np.stack([df[i].values for i in cont_features], axis=1)\ncont_values = torch.tensor(cont_values,dtype=torch.float)\ncont_values","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:35:57.456956Z","iopub.execute_input":"2022-06-03T09:35:57.458914Z","iopub.status.idle":"2022-06-03T09:35:57.468717Z","shell.execute_reply.started":"2022-06-03T09:35:57.458881Z","shell.execute_reply":"2022-06-03T09:35:57.467867Z"},"trusted":true},"execution_count":98,"outputs":[{"execution_count":98,"output_type":"execute_result","data":{"text/plain":"tensor([[   65.,  8450.,   856.,   854.,    19.],\n        [   80.,  9600.,  1262.,     0.,    46.],\n        [   68., 11250.,   920.,   866.,    21.],\n        ...,\n        [   66.,  9042.,  1188.,  1152.,    81.],\n        [   68.,  9717.,  1078.,     0.,    72.],\n        [   75.,  9937.,  1256.,     0.,    57.]])"},"metadata":{}}]},{"cell_type":"code","source":"cont_values.dtype","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:35:57.578163Z","iopub.execute_input":"2022-06-03T09:35:57.578824Z","iopub.status.idle":"2022-06-03T09:35:57.589908Z","shell.execute_reply.started":"2022-06-03T09:35:57.578779Z","shell.execute_reply":"2022-06-03T09:35:57.588539Z"},"trusted":true},"execution_count":99,"outputs":[{"execution_count":99,"output_type":"execute_result","data":{"text/plain":"torch.float32"},"metadata":{}}]},{"cell_type":"code","source":"### dependent feature\ny = torch.tensor(df['SalePrice'].values,dtype=torch.float).reshape(-1,1)\ny","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:35:57.738233Z","iopub.execute_input":"2022-06-03T09:35:57.738664Z","iopub.status.idle":"2022-06-03T09:35:57.755390Z","shell.execute_reply.started":"2022-06-03T09:35:57.738623Z","shell.execute_reply":"2022-06-03T09:35:57.754734Z"},"trusted":true},"execution_count":100,"outputs":[{"execution_count":100,"output_type":"execute_result","data":{"text/plain":"tensor([[208500.],\n        [181500.],\n        [223500.],\n        ...,\n        [266500.],\n        [142125.],\n        [147500.]])"},"metadata":{}}]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:35:57.927989Z","iopub.execute_input":"2022-06-03T09:35:57.928410Z","iopub.status.idle":"2022-06-03T09:35:57.957368Z","shell.execute_reply.started":"2022-06-03T09:35:57.928373Z","shell.execute_reply":"2022-06-03T09:35:57.956608Z"},"trusted":true},"execution_count":101,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 1201 entries, 0 to 1459\nData columns (total 10 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   MSSubClass   1201 non-null   int64  \n 1   MSZoning     1201 non-null   int64  \n 2   LotFrontage  1201 non-null   float64\n 3   LotArea      1201 non-null   int64  \n 4   Street       1201 non-null   int64  \n 5   LotShape     1201 non-null   int64  \n 6   1stFlrSF     1201 non-null   int64  \n 7   2ndFlrSF     1201 non-null   int64  \n 8   SalePrice    1201 non-null   int64  \n 9   Total Years  1201 non-null   int64  \ndtypes: float64(1), int64(9)\nmemory usage: 103.2 KB\n","output_type":"stream"}]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:35:58.098967Z","iopub.execute_input":"2022-06-03T09:35:58.099462Z","iopub.status.idle":"2022-06-03T09:35:58.106970Z","shell.execute_reply.started":"2022-06-03T09:35:58.099412Z","shell.execute_reply":"2022-06-03T09:35:58.105960Z"},"trusted":true},"execution_count":102,"outputs":[{"execution_count":102,"output_type":"execute_result","data":{"text/plain":"(1201, 10)"},"metadata":{}}]},{"cell_type":"code","source":"cat_features.shape, cont_values.shape, y.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:35:58.263383Z","iopub.execute_input":"2022-06-03T09:35:58.263833Z","iopub.status.idle":"2022-06-03T09:35:58.273663Z","shell.execute_reply.started":"2022-06-03T09:35:58.263795Z","shell.execute_reply":"2022-06-03T09:35:58.272734Z"},"trusted":true},"execution_count":103,"outputs":[{"execution_count":103,"output_type":"execute_result","data":{"text/plain":"(torch.Size([1201, 4]), torch.Size([1201, 5]), torch.Size([1201, 1]))"},"metadata":{}}]},{"cell_type":"code","source":"len(df['MSSubClass'].unique())","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:35:58.437062Z","iopub.execute_input":"2022-06-03T09:35:58.437438Z","iopub.status.idle":"2022-06-03T09:35:58.444930Z","shell.execute_reply.started":"2022-06-03T09:35:58.437405Z","shell.execute_reply":"2022-06-03T09:35:58.444001Z"},"trusted":true},"execution_count":104,"outputs":[{"execution_count":104,"output_type":"execute_result","data":{"text/plain":"15"},"metadata":{}}]},{"cell_type":"markdown","source":"## Embedding Layers ---> Categorical Features","metadata":{}},{"cell_type":"code","source":"cat_dims = [len(df[col].unique()) for col in [\"MSSubClass\", \"MSZoning\", \"Street\", \"LotShape\"]]","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:35:58.577461Z","iopub.execute_input":"2022-06-03T09:35:58.577858Z","iopub.status.idle":"2022-06-03T09:35:58.585723Z","shell.execute_reply.started":"2022-06-03T09:35:58.577823Z","shell.execute_reply":"2022-06-03T09:35:58.584610Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"cat_dims","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:35:58.762337Z","iopub.execute_input":"2022-06-03T09:35:58.762752Z","iopub.status.idle":"2022-06-03T09:35:58.768134Z","shell.execute_reply.started":"2022-06-03T09:35:58.762707Z","shell.execute_reply":"2022-06-03T09:35:58.767382Z"},"trusted":true},"execution_count":106,"outputs":[{"execution_count":106,"output_type":"execute_result","data":{"text/plain":"[15, 5, 2, 4]"},"metadata":{}}]},{"cell_type":"code","source":"##### output dimension should be setbased on the input dimension(min(50,feature dimension/2))\nembedding_dim = [(x, min(50, (x+1)//2)) for x in cat_dims]\nembedding_dim","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:35:58.937422Z","iopub.execute_input":"2022-06-03T09:35:58.938036Z","iopub.status.idle":"2022-06-03T09:35:58.944176Z","shell.execute_reply.started":"2022-06-03T09:35:58.937996Z","shell.execute_reply":"2022-06-03T09:35:58.943381Z"},"trusted":true},"execution_count":107,"outputs":[{"execution_count":107,"output_type":"execute_result","data":{"text/plain":"[(15, 8), (5, 3), (2, 1), (4, 2)]"},"metadata":{}}]},{"cell_type":"markdown","source":" Should not be greater than `50`","metadata":{}},{"cell_type":"code","source":"## above outputs looks like\n(15+1)//2","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:35:59.097105Z","iopub.execute_input":"2022-06-03T09:35:59.098099Z","iopub.status.idle":"2022-06-03T09:35:59.107208Z","shell.execute_reply.started":"2022-06-03T09:35:59.098060Z","shell.execute_reply":"2022-06-03T09:35:59.106340Z"},"trusted":true},"execution_count":108,"outputs":[{"execution_count":108,"output_type":"execute_result","data":{"text/plain":"8"},"metadata":{}}]},{"cell_type":"markdown","source":"# Model training using PyTorch","metadata":{}},{"cell_type":"code","source":"import torch.nn.functional as f\nembed_repr = nn.ModuleList([nn.Embedding(inp,out) for inp, out in embedding_dim])\nembed_repr","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:35:59.377760Z","iopub.execute_input":"2022-06-03T09:35:59.378345Z","iopub.status.idle":"2022-06-03T09:35:59.387481Z","shell.execute_reply.started":"2022-06-03T09:35:59.378310Z","shell.execute_reply":"2022-06-03T09:35:59.386470Z"},"trusted":true},"execution_count":109,"outputs":[{"execution_count":109,"output_type":"execute_result","data":{"text/plain":"ModuleList(\n  (0): Embedding(15, 8)\n  (1): Embedding(5, 3)\n  (2): Embedding(2, 1)\n  (3): Embedding(4, 2)\n)"},"metadata":{}}]},{"cell_type":"code","source":"cat_features","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:35:59.557924Z","iopub.execute_input":"2022-06-03T09:35:59.558230Z","iopub.status.idle":"2022-06-03T09:35:59.565758Z","shell.execute_reply.started":"2022-06-03T09:35:59.558204Z","shell.execute_reply":"2022-06-03T09:35:59.564832Z"},"trusted":true},"execution_count":110,"outputs":[{"execution_count":110,"output_type":"execute_result","data":{"text/plain":"tensor([[5, 3, 1, 3],\n        [0, 3, 1, 3],\n        [5, 3, 1, 0],\n        ...,\n        [6, 3, 1, 3],\n        [0, 3, 1, 3],\n        [0, 3, 1, 3]])"},"metadata":{}}]},{"cell_type":"code","source":"cat_featuresz = cat_features[:4]\ncat_featuresz","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:35:59.697419Z","iopub.execute_input":"2022-06-03T09:35:59.698029Z","iopub.status.idle":"2022-06-03T09:35:59.704653Z","shell.execute_reply.started":"2022-06-03T09:35:59.697995Z","shell.execute_reply":"2022-06-03T09:35:59.703721Z"},"trusted":true},"execution_count":111,"outputs":[{"execution_count":111,"output_type":"execute_result","data":{"text/plain":"tensor([[5, 3, 1, 3],\n        [0, 3, 1, 3],\n        [5, 3, 1, 0],\n        [6, 3, 1, 0]])"},"metadata":{}}]},{"cell_type":"code","source":"pd.set_option('display.max_rows', 500)\nembedding_val=[]\nfor i,e in enumerate(embed_repr):\n    embedding_val.append(e(cat_features[:,i]))","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:36:55.958817Z","iopub.execute_input":"2022-06-03T09:36:55.959206Z","iopub.status.idle":"2022-06-03T09:36:55.965375Z","shell.execute_reply.started":"2022-06-03T09:36:55.959173Z","shell.execute_reply":"2022-06-03T09:36:55.964579Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"code","source":"embedding_val","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:36:57.382206Z","iopub.execute_input":"2022-06-03T09:36:57.382556Z","iopub.status.idle":"2022-06-03T09:36:57.393707Z","shell.execute_reply.started":"2022-06-03T09:36:57.382527Z","shell.execute_reply":"2022-06-03T09:36:57.392723Z"},"trusted":true},"execution_count":129,"outputs":[{"execution_count":129,"output_type":"execute_result","data":{"text/plain":"[tensor([[-1.9793, -0.0901, -0.8985,  ..., -0.7198, -1.2037,  0.3494],\n         [ 0.3159,  0.5459, -2.0745,  ..., -1.5762, -0.7999, -1.1375],\n         [-1.9793, -0.0901, -0.8985,  ..., -0.7198, -1.2037,  0.3494],\n         ...,\n         [-0.4923, -0.4153, -0.8417,  ..., -1.0691,  0.3482,  1.8118],\n         [ 0.3159,  0.5459, -2.0745,  ..., -1.5762, -0.7999, -1.1375],\n         [ 0.3159,  0.5459, -2.0745,  ..., -1.5762, -0.7999, -1.1375]],\n        grad_fn=<EmbeddingBackward0>),\n tensor([[ 1.3749, -0.3629,  0.0708],\n         [ 1.3749, -0.3629,  0.0708],\n         [ 1.3749, -0.3629,  0.0708],\n         ...,\n         [ 1.3749, -0.3629,  0.0708],\n         [ 1.3749, -0.3629,  0.0708],\n         [ 1.3749, -0.3629,  0.0708]], grad_fn=<EmbeddingBackward0>),\n tensor([[-0.2052],\n         [-0.2052],\n         [-0.2052],\n         ...,\n         [-0.2052],\n         [-0.2052],\n         [-0.2052]], grad_fn=<EmbeddingBackward0>),\n tensor([[ 0.9169, -0.6593],\n         [ 0.9169, -0.6593],\n         [ 1.0195,  0.2138],\n         ...,\n         [ 0.9169, -0.6593],\n         [ 0.9169, -0.6593],\n         [ 0.9169, -0.6593]], grad_fn=<EmbeddingBackward0>)]"},"metadata":{}}]},{"cell_type":"markdown","source":"#### stacking the above result","metadata":{}},{"cell_type":"code","source":"z = torch.cat(embedding_val,1)\nz","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:37:05.637062Z","iopub.execute_input":"2022-06-03T09:37:05.637662Z","iopub.status.idle":"2022-06-03T09:37:05.644881Z","shell.execute_reply.started":"2022-06-03T09:37:05.637624Z","shell.execute_reply":"2022-06-03T09:37:05.644087Z"},"trusted":true},"execution_count":130,"outputs":[{"execution_count":130,"output_type":"execute_result","data":{"text/plain":"tensor([[-1.9793, -0.0901, -0.8985,  ..., -0.2052,  0.9169, -0.6593],\n        [ 0.3159,  0.5459, -2.0745,  ..., -0.2052,  0.9169, -0.6593],\n        [-1.9793, -0.0901, -0.8985,  ..., -0.2052,  1.0195,  0.2138],\n        ...,\n        [-0.4923, -0.4153, -0.8417,  ..., -0.2052,  0.9169, -0.6593],\n        [ 0.3159,  0.5459, -2.0745,  ..., -0.2052,  0.9169, -0.6593],\n        [ 0.3159,  0.5459, -2.0745,  ..., -0.2052,  0.9169, -0.6593]],\n       grad_fn=<CatBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"## Dropout layer\ndropout = nn.Dropout(.4)","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:37:23.678013Z","iopub.execute_input":"2022-06-03T09:37:23.678921Z","iopub.status.idle":"2022-06-03T09:37:23.683026Z","shell.execute_reply.started":"2022-06-03T09:37:23.678873Z","shell.execute_reply":"2022-06-03T09:37:23.681996Z"},"trusted":true},"execution_count":131,"outputs":[]},{"cell_type":"code","source":"final_embed = dropout(z)\nfinal_embed","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:37:25.377130Z","iopub.execute_input":"2022-06-03T09:37:25.377480Z","iopub.status.idle":"2022-06-03T09:37:25.385514Z","shell.execute_reply.started":"2022-06-03T09:37:25.377449Z","shell.execute_reply":"2022-06-03T09:37:25.384726Z"},"trusted":true},"execution_count":132,"outputs":[{"execution_count":132,"output_type":"execute_result","data":{"text/plain":"tensor([[-0.0000, -0.1502, -1.4975,  ..., -0.3420,  1.5282, -0.0000],\n        [ 0.5265,  0.9098, -3.4576,  ..., -0.0000,  1.5282, -1.0989],\n        [-3.2988, -0.1502, -1.4975,  ..., -0.3420,  0.0000,  0.3564],\n        ...,\n        [-0.8205, -0.0000, -0.0000,  ..., -0.0000,  0.0000, -1.0989],\n        [ 0.5265,  0.0000, -3.4576,  ..., -0.0000,  1.5282, -0.0000],\n        [ 0.5265,  0.9098, -0.0000,  ..., -0.3420,  0.0000, -0.0000]],\n       grad_fn=<MulBackward0>)"},"metadata":{}}]},{"cell_type":"markdown","source":"- Some of the values becomes 0 using Dropout layer to avoid overfitting","metadata":{}},{"cell_type":"code","source":"## feed forward neural network\nimport torch\nimport torch.nn as nn\n\n\nclass FeedForwardNN(nn.Module):\n\n    def __init__(self, embedding_dim, n_cont, out_sz, layers, p=0.5):\n        super().__init__()\n        self.embeds = nn.ModuleList([nn.Embedding(inp,out) for inp,out in embedding_dim])\n        self.emb_drop = nn.Dropout(p)\n        self.bn_cont = nn.BatchNorm1d(n_cont)\n        \n        layerlist = []\n        n_emb = sum((out for inp,out in embedding_dim))\n        n_in = n_emb + n_cont\n        \n        for i in layers:\n            layerlist.append(nn.Linear(n_in,i)) \n            layerlist.append(nn.ReLU(inplace=True))\n            layerlist.append(nn.BatchNorm1d(i))\n            layerlist.append(nn.Dropout(p))\n            n_in = i\n        layerlist.append(nn.Linear(layers[-1],out_sz))\n            \n        self.layers = nn.Sequential(*layerlist)\n    \n    def forward(self, x_cat, x_cont):\n        embeddings = []\n        for i,e in enumerate(self.embeds):\n            embeddings.append(e(x_cat[:,i]))\n        x = torch.cat(embeddings, 1)\n        x = self.emb_drop(x)\n        \n        x_cont = self.bn_cont(x_cont)\n        x = torch.cat([x, x_cont], 1)\n        x = self.layers(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:38:17.908631Z","iopub.execute_input":"2022-06-03T09:38:17.909238Z","iopub.status.idle":"2022-06-03T09:38:17.920009Z","shell.execute_reply.started":"2022-06-03T09:38:17.909200Z","shell.execute_reply":"2022-06-03T09:38:17.919194Z"},"trusted":true},"execution_count":133,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(100)\nmodel = FeedForwardNN(embedding_dim,len(cont_features),1,[100,50], p=0.4)","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:38:19.196992Z","iopub.execute_input":"2022-06-03T09:38:19.197345Z","iopub.status.idle":"2022-06-03T09:38:19.206235Z","shell.execute_reply.started":"2022-06-03T09:38:19.197315Z","shell.execute_reply":"2022-06-03T09:38:19.205365Z"},"trusted":true},"execution_count":134,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:38:19.797307Z","iopub.execute_input":"2022-06-03T09:38:19.797887Z","iopub.status.idle":"2022-06-03T09:38:19.803385Z","shell.execute_reply.started":"2022-06-03T09:38:19.797854Z","shell.execute_reply":"2022-06-03T09:38:19.802587Z"},"trusted":true},"execution_count":135,"outputs":[{"execution_count":135,"output_type":"execute_result","data":{"text/plain":"FeedForwardNN(\n  (embeds): ModuleList(\n    (0): Embedding(15, 8)\n    (1): Embedding(5, 3)\n    (2): Embedding(2, 1)\n    (3): Embedding(4, 2)\n  )\n  (emb_drop): Dropout(p=0.4, inplace=False)\n  (bn_cont): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (layers): Sequential(\n    (0): Linear(in_features=19, out_features=100, bias=True)\n    (1): ReLU(inplace=True)\n    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): Dropout(p=0.4, inplace=False)\n    (4): Linear(in_features=100, out_features=50, bias=True)\n    (5): ReLU(inplace=True)\n    (6): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (7): Dropout(p=0.4, inplace=False)\n    (8): Linear(in_features=50, out_features=1, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"### Loss and Optimizer","metadata":{}},{"cell_type":"code","source":"loss_function = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(),lr=0.01)","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:38:20.406874Z","iopub.execute_input":"2022-06-03T09:38:20.407536Z","iopub.status.idle":"2022-06-03T09:38:20.412008Z","shell.execute_reply.started":"2022-06-03T09:38:20.407504Z","shell.execute_reply":"2022-06-03T09:38:20.411017Z"},"trusted":true},"execution_count":136,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:38:20.697800Z","iopub.execute_input":"2022-06-03T09:38:20.699965Z","iopub.status.idle":"2022-06-03T09:38:20.709740Z","shell.execute_reply.started":"2022-06-03T09:38:20.699919Z","shell.execute_reply":"2022-06-03T09:38:20.708831Z"},"trusted":true},"execution_count":137,"outputs":[{"execution_count":137,"output_type":"execute_result","data":{"text/plain":"(1201, 10)"},"metadata":{}}]},{"cell_type":"code","source":"model.parameters","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:38:20.896731Z","iopub.execute_input":"2022-06-03T09:38:20.897037Z","iopub.status.idle":"2022-06-03T09:38:20.902216Z","shell.execute_reply.started":"2022-06-03T09:38:20.897011Z","shell.execute_reply":"2022-06-03T09:38:20.901495Z"},"trusted":true},"execution_count":138,"outputs":[{"execution_count":138,"output_type":"execute_result","data":{"text/plain":"<bound method Module.parameters of FeedForwardNN(\n  (embeds): ModuleList(\n    (0): Embedding(15, 8)\n    (1): Embedding(5, 3)\n    (2): Embedding(2, 1)\n    (3): Embedding(4, 2)\n  )\n  (emb_drop): Dropout(p=0.4, inplace=False)\n  (bn_cont): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (layers): Sequential(\n    (0): Linear(in_features=19, out_features=100, bias=True)\n    (1): ReLU(inplace=True)\n    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): Dropout(p=0.4, inplace=False)\n    (4): Linear(in_features=100, out_features=50, bias=True)\n    (5): ReLU(inplace=True)\n    (6): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (7): Dropout(p=0.4, inplace=False)\n    (8): Linear(in_features=50, out_features=1, bias=True)\n  )\n)>"},"metadata":{}}]},{"cell_type":"code","source":"cont_values","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:38:21.077895Z","iopub.execute_input":"2022-06-03T09:38:21.078537Z","iopub.status.idle":"2022-06-03T09:38:21.086334Z","shell.execute_reply.started":"2022-06-03T09:38:21.078506Z","shell.execute_reply":"2022-06-03T09:38:21.085373Z"},"trusted":true},"execution_count":139,"outputs":[{"execution_count":139,"output_type":"execute_result","data":{"text/plain":"tensor([[   65.,  8450.,   856.,   854.,    19.],\n        [   80.,  9600.,  1262.,     0.,    46.],\n        [   68., 11250.,   920.,   866.,    21.],\n        ...,\n        [   66.,  9042.,  1188.,  1152.,    81.],\n        [   68.,  9717.,  1078.,     0.,    72.],\n        [   75.,  9937.,  1256.,     0.,    57.]])"},"metadata":{}}]},{"cell_type":"code","source":"cont_values.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:38:21.416768Z","iopub.execute_input":"2022-06-03T09:38:21.417413Z","iopub.status.idle":"2022-06-03T09:38:21.422575Z","shell.execute_reply.started":"2022-06-03T09:38:21.417381Z","shell.execute_reply":"2022-06-03T09:38:21.421754Z"},"trusted":true},"execution_count":140,"outputs":[{"execution_count":140,"output_type":"execute_result","data":{"text/plain":"torch.Size([1201, 5])"},"metadata":{}}]},{"cell_type":"code","source":"batch_size = 1200\ntest_size = int(batch_size*0.15)\ntrain_categorical = cat_features[:batch_size-test_size]\ntest_categorical = cat_features[batch_size-test_size:batch_size]\ntrain_cont = cont_values[:batch_size-test_size]\ntest_cont = cont_values[batch_size-test_size:batch_size]\ny_train = y[:batch_size-test_size]\ny_test = y[batch_size-test_size:batch_size]","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:38:21.537433Z","iopub.execute_input":"2022-06-03T09:38:21.537749Z","iopub.status.idle":"2022-06-03T09:38:21.543022Z","shell.execute_reply.started":"2022-06-03T09:38:21.537720Z","shell.execute_reply":"2022-06-03T09:38:21.542289Z"},"trusted":true},"execution_count":141,"outputs":[]},{"cell_type":"code","source":"len(train_categorical), len(test_categorical), len(train_cont), len(test_cont), len(y_train), len(y_test)","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:38:21.837009Z","iopub.execute_input":"2022-06-03T09:38:21.837421Z","iopub.status.idle":"2022-06-03T09:38:21.846745Z","shell.execute_reply.started":"2022-06-03T09:38:21.837391Z","shell.execute_reply":"2022-06-03T09:38:21.845982Z"},"trusted":true},"execution_count":142,"outputs":[{"execution_count":142,"output_type":"execute_result","data":{"text/plain":"(1020, 180, 1020, 180, 1020, 180)"},"metadata":{}}]},{"cell_type":"code","source":"epochs=5000\nfinal_losses=[]\nfor i in range(epochs):\n    i=i+1\n    y_pred=model(train_categorical,train_cont)\n    loss=torch.sqrt(loss_function(y_pred,y_train)) ### RMSE\n    final_losses.append(loss)\n    if i%10==1:\n        print(\"Epoch number: {} and the loss : {}\".format(i,loss.item()))\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:39:22.857817Z","iopub.execute_input":"2022-06-03T09:39:22.858421Z","iopub.status.idle":"2022-06-03T09:39:48.676760Z","shell.execute_reply.started":"2022-06-03T09:39:22.858335Z","shell.execute_reply":"2022-06-03T09:39:48.671835Z"},"trusted":true},"execution_count":144,"outputs":[{"name":"stdout","text":"Epoch number: 1 and the loss : 200496.78125\nEpoch number: 11 and the loss : 200493.625\nEpoch number: 21 and the loss : 200489.0\nEpoch number: 31 and the loss : 200482.515625\nEpoch number: 41 and the loss : 200473.6875\nEpoch number: 51 and the loss : 200461.859375\nEpoch number: 61 and the loss : 200447.15625\nEpoch number: 71 and the loss : 200428.5\nEpoch number: 81 and the loss : 200407.375\nEpoch number: 91 and the loss : 200383.71875\nEpoch number: 101 and the loss : 200354.0625\nEpoch number: 111 and the loss : 200324.1875\nEpoch number: 121 and the loss : 200290.203125\nEpoch number: 131 and the loss : 200251.015625\nEpoch number: 141 and the loss : 200207.578125\nEpoch number: 151 and the loss : 200157.40625\nEpoch number: 161 and the loss : 200115.078125\nEpoch number: 171 and the loss : 200067.3125\nEpoch number: 181 and the loss : 200002.328125\nEpoch number: 191 and the loss : 199939.9375\nEpoch number: 201 and the loss : 199873.328125\nEpoch number: 211 and the loss : 199812.703125\nEpoch number: 221 and the loss : 199738.65625\nEpoch number: 231 and the loss : 199666.328125\nEpoch number: 241 and the loss : 199587.8125\nEpoch number: 251 and the loss : 199505.34375\nEpoch number: 261 and the loss : 199417.9375\nEpoch number: 271 and the loss : 199326.25\nEpoch number: 281 and the loss : 199229.515625\nEpoch number: 291 and the loss : 199127.875\nEpoch number: 301 and the loss : 199034.609375\nEpoch number: 311 and the loss : 198934.203125\nEpoch number: 321 and the loss : 198827.34375\nEpoch number: 331 and the loss : 198690.375\nEpoch number: 341 and the loss : 198610.671875\nEpoch number: 351 and the loss : 198498.25\nEpoch number: 361 and the loss : 198374.25\nEpoch number: 371 and the loss : 198250.53125\nEpoch number: 381 and the loss : 198139.125\nEpoch number: 391 and the loss : 198006.4375\nEpoch number: 401 and the loss : 197837.53125\nEpoch number: 411 and the loss : 197730.5625\nEpoch number: 421 and the loss : 197542.546875\nEpoch number: 431 and the loss : 197433.515625\nEpoch number: 441 and the loss : 197292.8125\nEpoch number: 451 and the loss : 197149.265625\nEpoch number: 461 and the loss : 197008.859375\nEpoch number: 471 and the loss : 196879.125\nEpoch number: 481 and the loss : 196668.125\nEpoch number: 491 and the loss : 196560.4375\nEpoch number: 501 and the loss : 196357.609375\nEpoch number: 511 and the loss : 196184.140625\nEpoch number: 521 and the loss : 196026.5\nEpoch number: 531 and the loss : 195897.0\nEpoch number: 541 and the loss : 195667.171875\nEpoch number: 551 and the loss : 195459.25\nEpoch number: 561 and the loss : 195261.578125\nEpoch number: 571 and the loss : 195099.6875\nEpoch number: 581 and the loss : 194958.546875\nEpoch number: 591 and the loss : 194758.203125\nEpoch number: 601 and the loss : 194531.28125\nEpoch number: 611 and the loss : 194320.140625\nEpoch number: 621 and the loss : 194059.203125\nEpoch number: 631 and the loss : 193895.015625\nEpoch number: 641 and the loss : 193722.484375\nEpoch number: 651 and the loss : 193473.171875\nEpoch number: 661 and the loss : 193240.484375\nEpoch number: 671 and the loss : 193039.359375\nEpoch number: 681 and the loss : 192932.953125\nEpoch number: 691 and the loss : 192647.84375\nEpoch number: 701 and the loss : 192362.046875\nEpoch number: 711 and the loss : 192221.328125\nEpoch number: 721 and the loss : 191927.296875\nEpoch number: 731 and the loss : 191639.90625\nEpoch number: 741 and the loss : 191467.140625\nEpoch number: 751 and the loss : 191258.546875\nEpoch number: 761 and the loss : 190885.140625\nEpoch number: 771 and the loss : 190617.5625\nEpoch number: 781 and the loss : 190610.234375\nEpoch number: 791 and the loss : 190165.734375\nEpoch number: 801 and the loss : 190022.03125\nEpoch number: 811 and the loss : 189741.25\nEpoch number: 821 and the loss : 189550.3125\nEpoch number: 831 and the loss : 189026.546875\nEpoch number: 841 and the loss : 188920.71875\nEpoch number: 851 and the loss : 188748.84375\nEpoch number: 861 and the loss : 188409.40625\nEpoch number: 871 and the loss : 188016.921875\nEpoch number: 881 and the loss : 187735.765625\nEpoch number: 891 and the loss : 187577.640625\nEpoch number: 901 and the loss : 187319.015625\nEpoch number: 911 and the loss : 187064.625\nEpoch number: 921 and the loss : 186627.640625\nEpoch number: 931 and the loss : 186391.5625\nEpoch number: 941 and the loss : 186260.3125\nEpoch number: 951 and the loss : 186048.359375\nEpoch number: 961 and the loss : 185522.296875\nEpoch number: 971 and the loss : 185457.296875\nEpoch number: 981 and the loss : 184954.125\nEpoch number: 991 and the loss : 184653.15625\nEpoch number: 1001 and the loss : 184626.0625\nEpoch number: 1011 and the loss : 183948.15625\nEpoch number: 1021 and the loss : 183721.46875\nEpoch number: 1031 and the loss : 183409.6875\nEpoch number: 1041 and the loss : 183206.59375\nEpoch number: 1051 and the loss : 182788.234375\nEpoch number: 1061 and the loss : 182468.28125\nEpoch number: 1071 and the loss : 182238.34375\nEpoch number: 1081 and the loss : 182098.3125\nEpoch number: 1091 and the loss : 181539.5625\nEpoch number: 1101 and the loss : 181234.828125\nEpoch number: 1111 and the loss : 181080.984375\nEpoch number: 1121 and the loss : 180659.5625\nEpoch number: 1131 and the loss : 180359.515625\nEpoch number: 1141 and the loss : 179883.140625\nEpoch number: 1151 and the loss : 179631.109375\nEpoch number: 1161 and the loss : 179181.96875\nEpoch number: 1171 and the loss : 178875.5\nEpoch number: 1181 and the loss : 178321.796875\nEpoch number: 1191 and the loss : 177820.25\nEpoch number: 1201 and the loss : 178012.421875\nEpoch number: 1211 and the loss : 177320.15625\nEpoch number: 1221 and the loss : 177364.75\nEpoch number: 1231 and the loss : 176600.71875\nEpoch number: 1241 and the loss : 176329.734375\nEpoch number: 1251 and the loss : 175847.03125\nEpoch number: 1261 and the loss : 175801.96875\nEpoch number: 1271 and the loss : 175344.40625\nEpoch number: 1281 and the loss : 175017.484375\nEpoch number: 1291 and the loss : 174963.53125\nEpoch number: 1301 and the loss : 174162.03125\nEpoch number: 1311 and the loss : 174235.5\nEpoch number: 1321 and the loss : 173680.921875\nEpoch number: 1331 and the loss : 173085.859375\nEpoch number: 1341 and the loss : 172205.40625\nEpoch number: 1351 and the loss : 172388.875\nEpoch number: 1361 and the loss : 171874.9375\nEpoch number: 1371 and the loss : 171778.84375\nEpoch number: 1381 and the loss : 171550.15625\nEpoch number: 1391 and the loss : 171109.484375\nEpoch number: 1401 and the loss : 170288.390625\nEpoch number: 1411 and the loss : 169780.140625\nEpoch number: 1421 and the loss : 169604.875\nEpoch number: 1431 and the loss : 169176.0625\nEpoch number: 1441 and the loss : 169186.53125\nEpoch number: 1451 and the loss : 168290.421875\nEpoch number: 1461 and the loss : 168147.953125\nEpoch number: 1471 and the loss : 167261.03125\nEpoch number: 1481 and the loss : 167474.421875\nEpoch number: 1491 and the loss : 166604.34375\nEpoch number: 1501 and the loss : 166320.625\nEpoch number: 1511 and the loss : 166087.625\nEpoch number: 1521 and the loss : 165327.4375\nEpoch number: 1531 and the loss : 165040.140625\nEpoch number: 1541 and the loss : 164587.953125\nEpoch number: 1551 and the loss : 163986.78125\nEpoch number: 1561 and the loss : 164433.46875\nEpoch number: 1571 and the loss : 163778.375\nEpoch number: 1581 and the loss : 163033.34375\nEpoch number: 1591 and the loss : 163118.9375\nEpoch number: 1601 and the loss : 162584.53125\nEpoch number: 1611 and the loss : 161440.53125\nEpoch number: 1621 and the loss : 161643.71875\nEpoch number: 1631 and the loss : 160587.3125\nEpoch number: 1641 and the loss : 160654.9375\nEpoch number: 1651 and the loss : 160012.875\nEpoch number: 1661 and the loss : 159745.0\nEpoch number: 1671 and the loss : 160009.734375\nEpoch number: 1681 and the loss : 158510.109375\nEpoch number: 1691 and the loss : 157832.953125\nEpoch number: 1701 and the loss : 158145.09375\nEpoch number: 1711 and the loss : 157987.25\nEpoch number: 1721 and the loss : 157490.890625\nEpoch number: 1731 and the loss : 156280.28125\nEpoch number: 1741 and the loss : 156017.109375\nEpoch number: 1751 and the loss : 155653.125\nEpoch number: 1761 and the loss : 155287.5625\nEpoch number: 1771 and the loss : 155025.640625\nEpoch number: 1781 and the loss : 154081.734375\nEpoch number: 1791 and the loss : 154340.453125\nEpoch number: 1801 and the loss : 153897.765625\nEpoch number: 1811 and the loss : 152482.484375\nEpoch number: 1821 and the loss : 152374.125\nEpoch number: 1831 and the loss : 151881.53125\nEpoch number: 1841 and the loss : 151504.6875\nEpoch number: 1851 and the loss : 151230.453125\nEpoch number: 1861 and the loss : 150154.953125\nEpoch number: 1871 and the loss : 150184.390625\nEpoch number: 1881 and the loss : 150106.703125\nEpoch number: 1891 and the loss : 149454.921875\nEpoch number: 1901 and the loss : 149430.3125\nEpoch number: 1911 and the loss : 147898.546875\nEpoch number: 1921 and the loss : 147394.1875\nEpoch number: 1931 and the loss : 147147.25\nEpoch number: 1941 and the loss : 147140.125\nEpoch number: 1951 and the loss : 146044.703125\nEpoch number: 1961 and the loss : 146185.546875\nEpoch number: 1971 and the loss : 145725.859375\nEpoch number: 1981 and the loss : 144848.109375\nEpoch number: 1991 and the loss : 144978.640625\nEpoch number: 2001 and the loss : 144019.5625\nEpoch number: 2011 and the loss : 143397.859375\nEpoch number: 2021 and the loss : 143740.1875\nEpoch number: 2031 and the loss : 141505.671875\nEpoch number: 2041 and the loss : 141987.140625\nEpoch number: 2051 and the loss : 141634.109375\nEpoch number: 2061 and the loss : 140374.796875\nEpoch number: 2071 and the loss : 140112.703125\nEpoch number: 2081 and the loss : 139350.796875\nEpoch number: 2091 and the loss : 140126.46875\nEpoch number: 2101 and the loss : 139274.03125\nEpoch number: 2111 and the loss : 138742.90625\nEpoch number: 2121 and the loss : 138469.859375\nEpoch number: 2131 and the loss : 138208.5\nEpoch number: 2141 and the loss : 137355.75\nEpoch number: 2151 and the loss : 137242.84375\nEpoch number: 2161 and the loss : 136426.015625\nEpoch number: 2171 and the loss : 136158.1875\nEpoch number: 2181 and the loss : 135495.59375\nEpoch number: 2191 and the loss : 135398.984375\nEpoch number: 2201 and the loss : 134193.890625\nEpoch number: 2211 and the loss : 133934.796875\nEpoch number: 2221 and the loss : 133300.65625\nEpoch number: 2231 and the loss : 131799.0625\nEpoch number: 2241 and the loss : 132568.0625\nEpoch number: 2251 and the loss : 131293.34375\nEpoch number: 2261 and the loss : 131526.25\nEpoch number: 2271 and the loss : 131281.4375\nEpoch number: 2281 and the loss : 130008.7890625\nEpoch number: 2291 and the loss : 130455.1484375\nEpoch number: 2301 and the loss : 129203.765625\nEpoch number: 2311 and the loss : 128337.109375\nEpoch number: 2321 and the loss : 128966.078125\nEpoch number: 2331 and the loss : 128321.1484375\nEpoch number: 2341 and the loss : 126704.8515625\nEpoch number: 2351 and the loss : 127043.1484375\nEpoch number: 2361 and the loss : 126418.4140625\nEpoch number: 2371 and the loss : 126694.4609375\nEpoch number: 2381 and the loss : 126130.421875\nEpoch number: 2391 and the loss : 124868.2578125\nEpoch number: 2401 and the loss : 124652.609375\nEpoch number: 2411 and the loss : 123572.578125\nEpoch number: 2421 and the loss : 123574.09375\nEpoch number: 2431 and the loss : 122754.3203125\nEpoch number: 2441 and the loss : 123111.796875\nEpoch number: 2451 and the loss : 121296.234375\nEpoch number: 2461 and the loss : 121398.3203125\nEpoch number: 2471 and the loss : 120342.7265625\nEpoch number: 2481 and the loss : 120519.765625\nEpoch number: 2491 and the loss : 120158.7578125\nEpoch number: 2501 and the loss : 119605.3125\nEpoch number: 2511 and the loss : 118351.546875\nEpoch number: 2521 and the loss : 118227.1640625\nEpoch number: 2531 and the loss : 116740.6015625\nEpoch number: 2541 and the loss : 117049.7890625\nEpoch number: 2551 and the loss : 117187.3671875\nEpoch number: 2561 and the loss : 116801.875\nEpoch number: 2571 and the loss : 114720.859375\nEpoch number: 2581 and the loss : 115561.703125\nEpoch number: 2591 and the loss : 114382.984375\nEpoch number: 2601 and the loss : 113897.3671875\nEpoch number: 2611 and the loss : 113953.640625\nEpoch number: 2621 and the loss : 112766.9140625\nEpoch number: 2631 and the loss : 113150.125\nEpoch number: 2641 and the loss : 111863.8046875\nEpoch number: 2651 and the loss : 114044.28125\nEpoch number: 2661 and the loss : 112454.890625\nEpoch number: 2671 and the loss : 111281.8046875\nEpoch number: 2681 and the loss : 109904.71875\nEpoch number: 2691 and the loss : 109901.2578125\nEpoch number: 2701 and the loss : 109207.0\nEpoch number: 2711 and the loss : 108589.828125\nEpoch number: 2721 and the loss : 108650.7734375\nEpoch number: 2731 and the loss : 107922.4140625\nEpoch number: 2741 and the loss : 108427.3359375\nEpoch number: 2751 and the loss : 106458.3515625\nEpoch number: 2761 and the loss : 107074.0859375\nEpoch number: 2771 and the loss : 105768.0859375\nEpoch number: 2781 and the loss : 104513.6640625\nEpoch number: 2791 and the loss : 105269.015625\nEpoch number: 2801 and the loss : 104703.671875\nEpoch number: 2811 and the loss : 103728.6484375\nEpoch number: 2821 and the loss : 102809.3046875\nEpoch number: 2831 and the loss : 102545.8125\nEpoch number: 2841 and the loss : 103731.75\nEpoch number: 2851 and the loss : 102430.8828125\nEpoch number: 2861 and the loss : 102468.375\nEpoch number: 2871 and the loss : 100847.3125\nEpoch number: 2881 and the loss : 101231.359375\nEpoch number: 2891 and the loss : 100092.953125\nEpoch number: 2901 and the loss : 99083.3671875\nEpoch number: 2911 and the loss : 98790.5546875\nEpoch number: 2921 and the loss : 98045.453125\nEpoch number: 2931 and the loss : 98289.9609375\nEpoch number: 2941 and the loss : 97353.34375\nEpoch number: 2951 and the loss : 99604.03125\nEpoch number: 2961 and the loss : 96785.9140625\nEpoch number: 2971 and the loss : 96606.7734375\nEpoch number: 2981 and the loss : 97764.296875\nEpoch number: 2991 and the loss : 95677.1015625\nEpoch number: 3001 and the loss : 93477.1796875\nEpoch number: 3011 and the loss : 94552.984375\nEpoch number: 3021 and the loss : 93984.109375\nEpoch number: 3031 and the loss : 93398.1015625\nEpoch number: 3041 and the loss : 92950.1328125\nEpoch number: 3051 and the loss : 92648.6484375\nEpoch number: 3061 and the loss : 91842.4765625\nEpoch number: 3071 and the loss : 89368.8515625\nEpoch number: 3081 and the loss : 90770.890625\nEpoch number: 3091 and the loss : 90119.6953125\nEpoch number: 3101 and the loss : 90549.234375\nEpoch number: 3111 and the loss : 90003.765625\nEpoch number: 3121 and the loss : 88568.2109375\nEpoch number: 3131 and the loss : 87819.359375\nEpoch number: 3141 and the loss : 87116.2734375\nEpoch number: 3151 and the loss : 87851.7421875\nEpoch number: 3161 and the loss : 86525.8984375\nEpoch number: 3171 and the loss : 87179.953125\nEpoch number: 3181 and the loss : 86098.671875\nEpoch number: 3191 and the loss : 86452.828125\nEpoch number: 3201 and the loss : 84625.609375\nEpoch number: 3211 and the loss : 83488.0390625\nEpoch number: 3221 and the loss : 83268.1875\nEpoch number: 3231 and the loss : 85359.8515625\nEpoch number: 3241 and the loss : 82921.015625\nEpoch number: 3251 and the loss : 81970.984375\nEpoch number: 3261 and the loss : 81176.0\nEpoch number: 3271 and the loss : 81647.59375\nEpoch number: 3281 and the loss : 81950.328125\nEpoch number: 3291 and the loss : 81816.765625\nEpoch number: 3301 and the loss : 79506.96875\nEpoch number: 3311 and the loss : 80047.15625\nEpoch number: 3321 and the loss : 78883.0\nEpoch number: 3331 and the loss : 78606.2890625\nEpoch number: 3341 and the loss : 78576.8359375\nEpoch number: 3351 and the loss : 78496.3984375\nEpoch number: 3361 and the loss : 76655.8671875\nEpoch number: 3371 and the loss : 76611.09375\nEpoch number: 3381 and the loss : 74946.7578125\nEpoch number: 3391 and the loss : 76225.375\nEpoch number: 3401 and the loss : 75432.9765625\nEpoch number: 3411 and the loss : 75163.3984375\nEpoch number: 3421 and the loss : 75203.359375\nEpoch number: 3431 and the loss : 73476.9453125\nEpoch number: 3441 and the loss : 73613.6875\nEpoch number: 3451 and the loss : 71748.2890625\nEpoch number: 3461 and the loss : 71841.859375\nEpoch number: 3471 and the loss : 70952.1015625\nEpoch number: 3481 and the loss : 71135.0859375\nEpoch number: 3491 and the loss : 70250.9765625\nEpoch number: 3501 and the loss : 69099.125\nEpoch number: 3511 and the loss : 70821.5078125\nEpoch number: 3521 and the loss : 70398.0078125\nEpoch number: 3531 and the loss : 68929.890625\nEpoch number: 3541 and the loss : 70810.859375\nEpoch number: 3551 and the loss : 67344.90625\nEpoch number: 3561 and the loss : 67337.046875\nEpoch number: 3571 and the loss : 66157.609375\nEpoch number: 3581 and the loss : 66544.59375\nEpoch number: 3591 and the loss : 66293.9453125\nEpoch number: 3601 and the loss : 66646.03125\nEpoch number: 3611 and the loss : 65179.56640625\nEpoch number: 3621 and the loss : 63655.78125\nEpoch number: 3631 and the loss : 64763.15625\nEpoch number: 3641 and the loss : 63596.859375\nEpoch number: 3651 and the loss : 63449.8515625\nEpoch number: 3661 and the loss : 63090.8828125\nEpoch number: 3671 and the loss : 62316.1015625\nEpoch number: 3681 and the loss : 61573.26171875\nEpoch number: 3691 and the loss : 60830.83984375\nEpoch number: 3701 and the loss : 61065.203125\nEpoch number: 3711 and the loss : 59974.2421875\nEpoch number: 3721 and the loss : 61619.79296875\nEpoch number: 3731 and the loss : 58012.25390625\nEpoch number: 3741 and the loss : 60071.1640625\nEpoch number: 3751 and the loss : 58894.33984375\nEpoch number: 3761 and the loss : 58962.23046875\nEpoch number: 3771 and the loss : 58781.9296875\nEpoch number: 3781 and the loss : 57524.765625\nEpoch number: 3791 and the loss : 57374.77734375\nEpoch number: 3801 and the loss : 56512.640625\nEpoch number: 3811 and the loss : 55885.19140625\nEpoch number: 3821 and the loss : 56046.05078125\nEpoch number: 3831 and the loss : 56350.671875\nEpoch number: 3841 and the loss : 53762.0625\nEpoch number: 3851 and the loss : 53384.59765625\nEpoch number: 3861 and the loss : 54372.703125\nEpoch number: 3871 and the loss : 53739.40234375\nEpoch number: 3881 and the loss : 54285.92578125\nEpoch number: 3891 and the loss : 52139.3046875\nEpoch number: 3901 and the loss : 53553.97265625\nEpoch number: 3911 and the loss : 52842.453125\nEpoch number: 3921 and the loss : 50912.85546875\nEpoch number: 3931 and the loss : 51835.51953125\nEpoch number: 3941 and the loss : 51571.32421875\nEpoch number: 3951 and the loss : 53800.80078125\nEpoch number: 3961 and the loss : 49095.390625\nEpoch number: 3971 and the loss : 50183.05078125\nEpoch number: 3981 and the loss : 49326.65625\nEpoch number: 3991 and the loss : 49688.0859375\nEpoch number: 4001 and the loss : 51093.046875\nEpoch number: 4011 and the loss : 49117.72265625\nEpoch number: 4021 and the loss : 47939.16796875\nEpoch number: 4031 and the loss : 48715.42578125\nEpoch number: 4041 and the loss : 47958.90625\nEpoch number: 4051 and the loss : 46654.20703125\nEpoch number: 4061 and the loss : 47345.18359375\nEpoch number: 4071 and the loss : 46382.5078125\nEpoch number: 4081 and the loss : 45076.16015625\nEpoch number: 4091 and the loss : 45103.19140625\nEpoch number: 4101 and the loss : 44842.97265625\nEpoch number: 4111 and the loss : 46283.51171875\nEpoch number: 4121 and the loss : 44762.296875\nEpoch number: 4131 and the loss : 45521.9140625\nEpoch number: 4141 and the loss : 44774.22265625\nEpoch number: 4151 and the loss : 43194.15234375\nEpoch number: 4161 and the loss : 45770.6796875\nEpoch number: 4171 and the loss : 44608.56640625\nEpoch number: 4181 and the loss : 42429.91015625\nEpoch number: 4191 and the loss : 43131.9921875\nEpoch number: 4201 and the loss : 43720.171875\nEpoch number: 4211 and the loss : 41668.89453125\nEpoch number: 4221 and the loss : 42968.046875\nEpoch number: 4231 and the loss : 41808.0390625\nEpoch number: 4241 and the loss : 40740.25\nEpoch number: 4251 and the loss : 40630.39453125\nEpoch number: 4261 and the loss : 40192.5\nEpoch number: 4271 and the loss : 42283.0703125\nEpoch number: 4281 and the loss : 42569.30078125\nEpoch number: 4291 and the loss : 40675.3125\nEpoch number: 4301 and the loss : 41464.36328125\nEpoch number: 4311 and the loss : 40288.2734375\nEpoch number: 4321 and the loss : 40693.83984375\nEpoch number: 4331 and the loss : 38659.7265625\nEpoch number: 4341 and the loss : 40871.34375\nEpoch number: 4351 and the loss : 40568.01953125\nEpoch number: 4361 and the loss : 40597.96484375\nEpoch number: 4371 and the loss : 38563.20703125\nEpoch number: 4381 and the loss : 40392.11328125\nEpoch number: 4391 and the loss : 39008.546875\nEpoch number: 4401 and the loss : 39331.4609375\nEpoch number: 4411 and the loss : 38875.1328125\nEpoch number: 4421 and the loss : 38019.1796875\nEpoch number: 4431 and the loss : 38283.65234375\nEpoch number: 4441 and the loss : 38099.32421875\nEpoch number: 4451 and the loss : 39925.08203125\nEpoch number: 4461 and the loss : 37905.98046875\nEpoch number: 4471 and the loss : 36246.47265625\nEpoch number: 4481 and the loss : 37919.42578125\nEpoch number: 4491 and the loss : 37269.078125\nEpoch number: 4501 and the loss : 34742.80078125\nEpoch number: 4511 and the loss : 37517.046875\nEpoch number: 4521 and the loss : 39419.51953125\nEpoch number: 4531 and the loss : 36404.8984375\nEpoch number: 4541 and the loss : 38737.19921875\nEpoch number: 4551 and the loss : 39145.0703125\nEpoch number: 4561 and the loss : 34765.00390625\nEpoch number: 4571 and the loss : 36801.0703125\nEpoch number: 4581 and the loss : 37464.16015625\nEpoch number: 4591 and the loss : 37452.89453125\nEpoch number: 4601 and the loss : 37723.4296875\nEpoch number: 4611 and the loss : 38044.96875\nEpoch number: 4621 and the loss : 36423.3046875\nEpoch number: 4631 and the loss : 37121.8203125\nEpoch number: 4641 and the loss : 36530.90234375\nEpoch number: 4651 and the loss : 36119.30859375\nEpoch number: 4661 and the loss : 36345.65625\nEpoch number: 4671 and the loss : 36084.83203125\nEpoch number: 4681 and the loss : 35002.890625\nEpoch number: 4691 and the loss : 36148.78125\nEpoch number: 4701 and the loss : 34212.375\nEpoch number: 4711 and the loss : 36290.828125\nEpoch number: 4721 and the loss : 37656.890625\nEpoch number: 4731 and the loss : 35133.8671875\nEpoch number: 4741 and the loss : 35508.05859375\nEpoch number: 4751 and the loss : 35491.14453125\nEpoch number: 4761 and the loss : 36941.8515625\nEpoch number: 4771 and the loss : 42437.703125\nEpoch number: 4781 and the loss : 36241.6875\nEpoch number: 4791 and the loss : 36683.5\nEpoch number: 4801 and the loss : 36067.93359375\nEpoch number: 4811 and the loss : 36578.515625\nEpoch number: 4821 and the loss : 36295.9453125\nEpoch number: 4831 and the loss : 36200.390625\nEpoch number: 4841 and the loss : 35905.5625\nEpoch number: 4851 and the loss : 37853.359375\nEpoch number: 4861 and the loss : 35808.921875\nEpoch number: 4871 and the loss : 35277.77734375\nEpoch number: 4881 and the loss : 36396.73828125\nEpoch number: 4891 and the loss : 35406.171875\nEpoch number: 4901 and the loss : 34702.46875\nEpoch number: 4911 and the loss : 36506.82421875\nEpoch number: 4921 and the loss : 35951.18359375\nEpoch number: 4931 and the loss : 36424.05078125\nEpoch number: 4941 and the loss : 36481.59375\nEpoch number: 4951 and the loss : 36186.7578125\nEpoch number: 4961 and the loss : 34783.51953125\nEpoch number: 4971 and the loss : 35820.33984375\nEpoch number: 4981 and the loss : 37312.9375\nEpoch number: 4991 and the loss : 36321.3671875\n","output_type":"stream"}]},{"cell_type":"code","source":"type(range(epochs))","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:43:07.132236Z","iopub.execute_input":"2022-06-03T09:43:07.132592Z","iopub.status.idle":"2022-06-03T09:43:07.137625Z","shell.execute_reply.started":"2022-06-03T09:43:07.132562Z","shell.execute_reply":"2022-06-03T09:43:07.136945Z"},"trusted":true},"execution_count":148,"outputs":[{"execution_count":148,"output_type":"execute_result","data":{"text/plain":"range"},"metadata":{}}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\nfi_loss = [fl.item() for fl in final_losses]\nplt.plot(range(epochs), fi_loss)\nplt.ylabel('RMSE Loss')\nplt.xlabel('epoch');","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:42:48.321880Z","iopub.execute_input":"2022-06-03T09:42:48.322448Z","iopub.status.idle":"2022-06-03T09:42:48.540357Z","shell.execute_reply.started":"2022-06-03T09:42:48.322412Z","shell.execute_reply":"2022-06-03T09:42:48.539561Z"},"trusted":true},"execution_count":147,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"## Validate the test data\ny_pred =\"\"\nwith torch.no_grad():\n    y_pred = model(test_categorical, test_cont)\n    loss = torch.sqrt(loss_function(y_pred, y_test))\nprint('RMSE: {}'.format(loss))","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:45:18.103119Z","iopub.execute_input":"2022-06-03T09:45:18.103488Z","iopub.status.idle":"2022-06-03T09:45:18.112621Z","shell.execute_reply.started":"2022-06-03T09:45:18.103456Z","shell.execute_reply":"2022-06-03T09:45:18.111746Z"},"trusted":true},"execution_count":151,"outputs":[{"name":"stdout","text":"RMSE: 44885.2890625\n","output_type":"stream"}]},{"cell_type":"code","source":"data_verify = pd.DataFrame(y_test.tolist(), columns=[\"Test\"])\ndata_predicted = pd.DataFrame(y_pred.tolist(),columns=[\"Prediction\"])","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:46:14.662934Z","iopub.execute_input":"2022-06-03T09:46:14.663282Z","iopub.status.idle":"2022-06-03T09:46:14.669588Z","shell.execute_reply.started":"2022-06-03T09:46:14.663253Z","shell.execute_reply":"2022-06-03T09:46:14.668738Z"},"trusted":true},"execution_count":152,"outputs":[]},{"cell_type":"code","source":"# data_predicted","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:46:38.142665Z","iopub.execute_input":"2022-06-03T09:46:38.143427Z","iopub.status.idle":"2022-06-03T09:46:38.147028Z","shell.execute_reply.started":"2022-06-03T09:46:38.143387Z","shell.execute_reply":"2022-06-03T09:46:38.146099Z"},"trusted":true},"execution_count":154,"outputs":[]},{"cell_type":"code","source":"final_output = pd.concat([data_verify, data_predicted],axis=1)\nfinal_output['Difference'] = final_output['Test']-final_output['Prediction']\nfinal_output.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:48:02.257172Z","iopub.execute_input":"2022-06-03T09:48:02.257526Z","iopub.status.idle":"2022-06-03T09:48:02.270327Z","shell.execute_reply.started":"2022-06-03T09:48:02.257496Z","shell.execute_reply":"2022-06-03T09:48:02.269333Z"},"trusted":true},"execution_count":155,"outputs":[{"execution_count":155,"output_type":"execute_result","data":{"text/plain":"       Test     Prediction    Difference\n0  130000.0  141486.125000 -11486.125000\n1  138887.0  189391.437500 -50504.437500\n2  175500.0  120932.687500  54567.312500\n3  195000.0  245629.421875 -50629.421875\n4  142500.0  144191.625000  -1691.625000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Test</th>\n      <th>Prediction</th>\n      <th>Difference</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>130000.0</td>\n      <td>141486.125000</td>\n      <td>-11486.125000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>138887.0</td>\n      <td>189391.437500</td>\n      <td>-50504.437500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>175500.0</td>\n      <td>120932.687500</td>\n      <td>54567.312500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>195000.0</td>\n      <td>245629.421875</td>\n      <td>-50629.421875</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>142500.0</td>\n      <td>144191.625000</td>\n      <td>-1691.625000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"## sacve the pytorch model\ntorch.save(model,'HousePrice.pt')\ntorch.save(model.state_dict(),'HouseWeights.pt')","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:49:17.163407Z","iopub.execute_input":"2022-06-03T09:49:17.163795Z","iopub.status.idle":"2022-06-03T09:49:17.177449Z","shell.execute_reply.started":"2022-06-03T09:49:17.163761Z","shell.execute_reply":"2022-06-03T09:49:17.176535Z"},"trusted":true},"execution_count":156,"outputs":[]},{"cell_type":"code","source":"## Loading the saved model\nembs_size = [(15,8),(5,3),(2,1),(4,2)]\nmodel1 = FeedForwardNN(embs_size, 5,1,[100,50],p=0.4)\nmodel1.load_state_dict(torch.load('HouseWeights.pt'))","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:50:46.482134Z","iopub.execute_input":"2022-06-03T09:50:46.482626Z","iopub.status.idle":"2022-06-03T09:50:46.497401Z","shell.execute_reply.started":"2022-06-03T09:50:46.482590Z","shell.execute_reply":"2022-06-03T09:50:46.496504Z"},"trusted":true},"execution_count":157,"outputs":[{"execution_count":157,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"model1.eval()","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:50:57.781971Z","iopub.execute_input":"2022-06-03T09:50:57.782322Z","iopub.status.idle":"2022-06-03T09:50:57.788195Z","shell.execute_reply.started":"2022-06-03T09:50:57.782293Z","shell.execute_reply":"2022-06-03T09:50:57.787454Z"},"trusted":true},"execution_count":158,"outputs":[{"execution_count":158,"output_type":"execute_result","data":{"text/plain":"FeedForwardNN(\n  (embeds): ModuleList(\n    (0): Embedding(15, 8)\n    (1): Embedding(5, 3)\n    (2): Embedding(2, 1)\n    (3): Embedding(4, 2)\n  )\n  (emb_drop): Dropout(p=0.4, inplace=False)\n  (bn_cont): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (layers): Sequential(\n    (0): Linear(in_features=19, out_features=100, bias=True)\n    (1): ReLU(inplace=True)\n    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): Dropout(p=0.4, inplace=False)\n    (4): Linear(in_features=100, out_features=50, bias=True)\n    (5): ReLU(inplace=True)\n    (6): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (7): Dropout(p=0.4, inplace=False)\n    (8): Linear(in_features=50, out_features=1, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"## The End","metadata":{}}]}